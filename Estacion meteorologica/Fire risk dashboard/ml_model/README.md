# ML Model Directory

This directory contains all machine learning components for the fire risk dashboard.

## Directory Structure

```
ml_model/
├── README.md                           # This file
├── prepare_training_data.py            # Step 1: Build training dataset
├── train_fire_model.py                 # Step 2: Train model
├── validate_model_agreement.py         # Statistical validation script
│
├── fire_model.pkl                      # Trained Random Forest model
├── training_data.csv                   # Training dataset (generated)
├── validation_results.json             # Validation statistics
│
├── data/                               # Raw data (gitignored)
│   └── cicatrices_incendios_resumen.geojson  # Historical fires from Dataverse
│
└── plots/                              # Evaluation plots
    ├── feature_importance.png          # Feature importance analysis
    ├── confusion_matrix.png            # Prediction accuracy breakdown
    ├── roc_curve.png                   # Model discrimination ability
    └── bland_altman.png                # Agreement analysis plot
```

## Quick Start

### 1. Run Dashboard (uses existing model)

From dashboard root:
```bash
conda activate fire_risk_dashboard
streamlit run app.py
```

The dashboard automatically loads `ml_model/fire_model.pkl` and displays ML predictions.


## Model Details

- **Algorithm**: Random Forest (100 trees)
- **Features**: temp_c, rh_pct, wind_kmh, days_no_rain (weather-only model)
- **Training data**: 616 fires + 616 non-fires from Araucania (1984-2018)
- **Current performance**: 87.8% accuracy, 0.94 ROC AUC

## Files Explanation

- **prepare_training_data.py**: Downloads historical fires, fetches weather data, creates balanced training set
- **train_fire_model.py**: Trains Random Forest, evaluates performance, saves model and plots
- **fire_model.pkl**: Trained model file loaded by main dashboard (`app.py`) - included in repo
- **training_data.csv**: Processed training dataset (temp, humidity, wind, dry days + fire/no-fire label) - **generated artifact, gitignored**
- **data/**: Raw fire dataset from Datos para Resiliencia - **generated artifact, gitignored** (downloads via `prepare_training_data.py`)
- **plots/**: Evaluation visualizations for presentations (generated by `train_fire_model.py`)

## Integration with Dashboard

The main dashboard (`../app.py`) loads the model:

```python
model = joblib.load("ml_model/fire_model.pkl")
```

For each day, it predicts fire probability:

```python
probability = model.predict_proba([[temp, humidity, wind, dry_days]])[0][1]
```

**Visualization:** The dashboard displays both risk metrics using dual semi-circular gauges that allow intuitive visual comparison between the rule-based risk index and ML fire probability. Color zones indicate risk levels (green/yellow/orange/red), and an agreement indicator shows whether the two methods are aligned.

## Statistical Validation

The dashboard includes statistical validation comparing the rule-based risk method and ML predictions. This validation uses actual historical fire data to determine if the two methods agree significantly.

### Running Validation

```bash
cd ml_model
python validate_model_agreement.py
```

This generates:
- `validation_results.json` - Statistical test results
- `plots/bland_altman.png` - Bland-Altman agreement plot

### Statistical Tests Performed

1. **McNemar's Test**: Tests for systematic disagreement between methods
   - p > 0.05 = no significant difference
   
2. **Concordance Correlation Coefficient (CCC)**: Measures agreement strength
   - ρc > 0.90 = strong agreement
   - ρc 0.75-0.90 = moderate agreement
   - ρc < 0.75 = poor agreement

3. **Bland-Altman Analysis**: Defines limits of agreement
   - Calculates mean difference and 95% confidence limits
   - Shows expected range of differences between methods

4. **Correlation Analysis**: Pearson and Spearman correlations

### Viewing Results in Dashboard

Click the information button next to the agreement indicator to view:
- Statistical test results
- Bland-Altman plot
- Interpretation of agreement status

The agreement indicator uses Bland-Altman limits (data-driven) rather than arbitrary thresholds.


